{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Collection = void 0;\nconst bson_1 = require(\"./bson\");\nconst ordered_1 = require(\"./bulk/ordered\");\nconst unordered_1 = require(\"./bulk/unordered\");\nconst change_stream_1 = require(\"./change_stream\");\nconst aggregation_cursor_1 = require(\"./cursor/aggregation_cursor\");\nconst find_cursor_1 = require(\"./cursor/find_cursor\");\nconst list_indexes_cursor_1 = require(\"./cursor/list_indexes_cursor\");\nconst list_search_indexes_cursor_1 = require(\"./cursor/list_search_indexes_cursor\");\nconst error_1 = require(\"./error\");\nconst count_1 = require(\"./operations/count\");\nconst delete_1 = require(\"./operations/delete\");\nconst distinct_1 = require(\"./operations/distinct\");\nconst estimated_document_count_1 = require(\"./operations/estimated_document_count\");\nconst execute_operation_1 = require(\"./operations/execute_operation\");\nconst find_and_modify_1 = require(\"./operations/find_and_modify\");\nconst indexes_1 = require(\"./operations/indexes\");\nconst insert_1 = require(\"./operations/insert\");\nconst rename_1 = require(\"./operations/rename\");\nconst create_1 = require(\"./operations/search_indexes/create\");\nconst drop_1 = require(\"./operations/search_indexes/drop\");\nconst update_1 = require(\"./operations/search_indexes/update\");\nconst update_2 = require(\"./operations/update\");\nconst read_concern_1 = require(\"./read_concern\");\nconst read_preference_1 = require(\"./read_preference\");\nconst utils_1 = require(\"./utils\");\nconst write_concern_1 = require(\"./write_concern\");\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nclass Collection {\n  /**\n   * Create a new Collection instance\n   * @internal\n   */\n  constructor(db, name, options) {\n    this.db = db;\n    // Internal state\n    this.s = {\n      db,\n      options,\n      namespace: new utils_1.MongoDBCollectionNamespace(db.databaseName, name),\n      pkFactory: db.options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n      readPreference: read_preference_1.ReadPreference.fromOptions(options),\n      bsonOptions: (0, bson_1.resolveBSONOptions)(options, db),\n      readConcern: read_concern_1.ReadConcern.fromOptions(options),\n      writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n    };\n    this.client = db.client;\n  }\n  /**\n   * The name of the database this collection belongs to\n   */\n  get dbName() {\n    return this.s.namespace.db;\n  }\n  /**\n   * The name of this collection\n   */\n  get collectionName() {\n    return this.s.namespace.collection;\n  }\n  /**\n   * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n   */\n  get namespace() {\n    return this.fullNamespace.toString();\n  }\n  /**\n   *  @internal\n   *\n   * The `MongoDBNamespace` for the collection.\n   */\n  get fullNamespace() {\n    return this.s.namespace;\n  }\n  /**\n   * The current readConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readConcern() {\n    if (this.s.readConcern == null) {\n      return this.db.readConcern;\n    }\n    return this.s.readConcern;\n  }\n  /**\n   * The current readPreference of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readPreference() {\n    if (this.s.readPreference == null) {\n      return this.db.readPreference;\n    }\n    return this.s.readPreference;\n  }\n  get bsonOptions() {\n    return this.s.bsonOptions;\n  }\n  /**\n   * The current writeConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get writeConcern() {\n    if (this.s.writeConcern == null) {\n      return this.db.writeConcern;\n    }\n    return this.s.writeConcern;\n  }\n  /** The current index hint for the collection */\n  get hint() {\n    return this.s.collectionHint;\n  }\n  set hint(v) {\n    this.s.collectionHint = (0, utils_1.normalizeHintField)(v);\n  }\n  get timeoutMS() {\n    return this.s.options.timeoutMS;\n  }\n  /**\n   * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param doc - The document to insert\n   * @param options - Optional settings for the command\n   */\n  async insertOne(doc, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertOneOperation(this, doc, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param docs - The documents to insert\n   * @param options - Optional settings for the command\n   */\n  async insertMany(docs, options) {\n    if (!Array.isArray(docs)) {\n      throw new error_1.MongoInvalidArgumentError('Argument \"docs\" must be an array of documents');\n    }\n    options = (0, utils_1.resolveOptions)(this, options ?? {});\n    const acknowledged = write_concern_1.WriteConcern.fromOptions(options)?.w !== 0;\n    try {\n      const res = await this.bulkWrite(docs.map(doc => ({\n        insertOne: {\n          document: doc\n        }\n      })), options);\n      return {\n        acknowledged,\n        insertedCount: res.insertedCount,\n        insertedIds: res.insertedIds\n      };\n    } catch (err) {\n      if (err && err.message === 'Operation must be an object with an operation key') {\n        throw new error_1.MongoInvalidArgumentError('Collection.insertMany() cannot be called with an array that has null/undefined values');\n      }\n      throw err;\n    }\n  }\n  /**\n   * Perform a bulkWrite operation without a fluent API\n   *\n   * Legal operation types are\n   * - `insertOne`\n   * - `replaceOne`\n   * - `updateOne`\n   * - `updateMany`\n   * - `deleteOne`\n   * - `deleteMany`\n   *\n   * If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param operations - Bulk operations to perform\n   * @param options - Optional settings for the command\n   * @throws MongoDriverError if operations is not an array\n   */\n  async bulkWrite(operations, options) {\n    if (!Array.isArray(operations)) {\n      throw new error_1.MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n    }\n    options = (0, utils_1.resolveOptions)(this, options ?? {});\n    // TODO(NODE-7071): remove once the client doesn't need to be connected to construct\n    // bulk operations\n    const isConnected = this.client.topology != null;\n    if (!isConnected) {\n      await (0, execute_operation_1.autoConnect)(this.client);\n    }\n    // Create the bulk operation\n    const bulk = options.ordered === false ? this.initializeUnorderedBulkOp(options) : this.initializeOrderedBulkOp(options);\n    // for each op go through and add to the bulk\n    for (const operation of operations) {\n      bulk.raw(operation);\n    }\n    // Execute the bulk\n    return await bulk.execute({\n      ...options\n    });\n  }\n  /**\n   * Update a single document in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateOne(filter, update, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateOneOperation(this.s.namespace, filter, update, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Replace a document in a collection with another document\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async replaceOne(filter, replacement, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new update_2.ReplaceOneOperation(this.s.namespace, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Update multiple documents in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateMany(filter, update, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateManyOperation(this.s.namespace, filter, update, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Delete a document from a collection\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteOne(filter = {}, options = {}) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteOneOperation(this.s.namespace, filter, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Delete multiple documents from a collection\n   *\n   * @param filter - The filter used to select the documents to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteMany(filter = {}, options = {}) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteManyOperation(this.s.namespace, filter, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Rename the collection.\n   *\n   * @remarks\n   * This operation does not inherit options from the Db or MongoClient.\n   *\n   * @param newName - New name of of the collection.\n   * @param options - Optional settings for the command\n   */\n  async rename(newName, options) {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this, newName, (0, utils_1.resolveOptions)(undefined, {\n      ...options,\n      readPreference: read_preference_1.ReadPreference.PRIMARY\n    })));\n  }\n  /**\n   * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async drop(options) {\n    return await this.db.dropCollection(this.collectionName, options);\n  }\n  async findOne(filter = {}, options = {}) {\n    // Explicitly set the limit to 1 and singleBatch to true for all commands, per the spec.\n    // noCursorTimeout must be unset as well as batchSize.\n    // See: https://github.com/mongodb/specifications/blob/master/source/crud/crud.md#findone-api-details\n    const {\n      ...opts\n    } = options;\n    opts.singleBatch = true;\n    const cursor = this.find(filter, opts).limit(1);\n    const result = await cursor.next();\n    await cursor.close();\n    return result;\n  }\n  find(filter = {}, options = {}) {\n    return new find_cursor_1.FindCursor(this.client, this.s.namespace, filter, (0, utils_1.resolveOptions)(this, options));\n  }\n  /**\n   * Returns the options of the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async options(options) {\n    options = (0, utils_1.resolveOptions)(this, options);\n    const [collection] = await this.db.listCollections({\n      name: this.collectionName\n    }, {\n      ...options,\n      nameOnly: false\n    }).toArray();\n    if (collection == null || collection.options == null) {\n      throw new error_1.MongoAPIError(`collection ${this.namespace} not found`);\n    }\n    return collection.options;\n  }\n  /**\n   * Returns if the collection is a capped collection\n   *\n   * @param options - Optional settings for the command\n   */\n  async isCapped(options) {\n    const {\n      capped\n    } = await this.options(options);\n    return Boolean(capped);\n  }\n  /**\n   * Creates an index on the db and collection collection.\n   *\n   * @param indexSpec - The field name or index specification to create an index for\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   *\n   * await collection.createIndex({ a: 1, b: -1 });\n   *\n   * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n   * await collection.createIndex([ [c, 1], [d, -1] ]);\n   *\n   * // Equivalent to { e: 1 }\n   * await collection.createIndex('e');\n   *\n   * // Equivalent to { f: 1, g: 1 }\n   * await collection.createIndex(['f', 'g'])\n   *\n   * // Equivalent to { h: 1, i: -1 }\n   * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n   *\n   * // Equivalent to { j: 1, k: -1, l: 2d }\n   * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n   * ```\n   */\n  async createIndex(indexSpec, options) {\n    const indexes = await (0, execute_operation_1.executeOperation)(this.client, indexes_1.CreateIndexesOperation.fromIndexSpecification(this, this.collectionName, indexSpec, (0, utils_1.resolveOptions)(this, options)));\n    return indexes[0];\n  }\n  /**\n   * Creates multiple indexes in the collection, this method is only supported for\n   * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n   * error.\n   *\n   * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n   * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n   *\n   * @param indexSpecs - An array of index specifications to be created\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   * await collection.createIndexes([\n   *   // Simple index on field fizz\n   *   {\n   *     key: { fizz: 1 },\n   *   }\n   *   // wildcard index\n   *   {\n   *     key: { '$**': 1 }\n   *   },\n   *   // named index on darmok and jalad\n   *   {\n   *     key: { darmok: 1, jalad: -1 }\n   *     name: 'tanagra'\n   *   }\n   * ]);\n   * ```\n   */\n  async createIndexes(indexSpecs, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, indexes_1.CreateIndexesOperation.fromIndexDescriptionArray(this, this.collectionName, indexSpecs, (0, utils_1.resolveOptions)(this, {\n      ...options,\n      maxTimeMS: undefined\n    })));\n  }\n  /**\n   * Drops an index from this collection.\n   *\n   * @param indexName - Name of the index to drop.\n   * @param options - Optional settings for the command\n   */\n  async dropIndex(indexName, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, indexName, {\n      ...(0, utils_1.resolveOptions)(this, options),\n      readPreference: read_preference_1.ReadPreference.primary\n    }));\n  }\n  /**\n   * Drops all indexes from this collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async dropIndexes(options) {\n    try {\n      await (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, '*', (0, utils_1.resolveOptions)(this, options)));\n      return true;\n    } catch (error) {\n      // TODO(NODE-6517): Driver should only filter for namespace not found error. Other errors should be thrown.\n      if (error instanceof error_1.MongoOperationTimeoutError) throw error;\n      return false;\n    }\n  }\n  /**\n   * Get the list of all indexes information for the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  listIndexes(options) {\n    return new list_indexes_cursor_1.ListIndexesCursor(this, (0, utils_1.resolveOptions)(this, options));\n  }\n  /**\n   * Checks if one or more indexes exist on the collection, fails on first non-existing index\n   *\n   * @param indexes - One or more index names to check.\n   * @param options - Optional settings for the command\n   */\n  async indexExists(indexes, options) {\n    const indexNames = Array.isArray(indexes) ? indexes : [indexes];\n    const allIndexes = new Set(await this.listIndexes(options).map(({\n      name\n    }) => name).toArray());\n    return indexNames.every(name => allIndexes.has(name));\n  }\n  async indexInformation(options) {\n    return await this.indexes({\n      ...options,\n      full: options?.full ?? false\n    });\n  }\n  /**\n   * Gets an estimate of the count of documents in a collection using collection metadata.\n   * This will always run a count command on all server versions.\n   *\n   * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n   * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n   * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n   * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n   * encountering errors.\n   *\n   * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n   * @param options - Optional settings for the command\n   */\n  async estimatedDocumentCount(options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new estimated_document_count_1.EstimatedDocumentCountOperation(this, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Gets the number of documents matching the filter.\n   * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * Due to countDocuments using the $match aggregation pipeline stage, certain query operators cannot be used in countDocuments. This includes the $where and $near query operators, among others. Details can be found in the documentation for the $match aggregation pipeline stage.\n   *\n   * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n   * the following query operators must be replaced:\n   *\n   * | Operator | Replacement |\n   * | -------- | ----------- |\n   * | `$where`   | [`$expr`][1] |\n   * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n   * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n   *\n   * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   *\n   * @param filter - The filter for the count\n   * @param options - Optional settings for the command\n   *\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   */\n  async countDocuments(filter = {}, options = {}) {\n    const pipeline = [];\n    pipeline.push({\n      $match: filter\n    });\n    if (typeof options.skip === 'number') {\n      pipeline.push({\n        $skip: options.skip\n      });\n    }\n    if (typeof options.limit === 'number') {\n      pipeline.push({\n        $limit: options.limit\n      });\n    }\n    pipeline.push({\n      $group: {\n        _id: 1,\n        n: {\n          $sum: 1\n        }\n      }\n    });\n    const cursor = this.aggregate(pipeline, options);\n    const doc = await cursor.next();\n    await cursor.close();\n    return doc?.n ?? 0;\n  }\n  async distinct(key, filter = {}, options = {}) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new distinct_1.DistinctOperation(this, key, filter, (0, utils_1.resolveOptions)(this, options)));\n  }\n  async indexes(options) {\n    const indexes = await this.listIndexes(options).toArray();\n    const full = options?.full ?? true;\n    if (full) {\n      return indexes;\n    }\n    const object = Object.fromEntries(indexes.map(({\n      name,\n      key\n    }) => [name, Object.entries(key)]));\n    return object;\n  }\n  async findOneAndDelete(filter, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndDeleteOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n  }\n  async findOneAndReplace(filter, replacement, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndReplaceOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n  }\n  async findOneAndUpdate(filter, update, options) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndUpdateOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n  }\n  /**\n   * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n   *\n   * @param pipeline - An array of aggregation pipelines to execute\n   * @param options - Optional settings for the command\n   */\n  aggregate(pipeline = [], options) {\n    if (!Array.isArray(pipeline)) {\n      throw new error_1.MongoInvalidArgumentError('Argument \"pipeline\" must be an array of aggregation stages');\n    }\n    return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n  }\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to override the schema that may be defined for this specific collection\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   * @example\n   * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n   * ```ts\n   * collection.watch<{ _id: number }>()\n   *   .on('change', change => console.log(change._id.toFixed(4)));\n   * ```\n   *\n   * @example\n   * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n   * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n   * No need start from scratch on the ChangeStreamInsertDocument type!\n   * By using an intersection we can save time and ensure defaults remain the same type!\n   * ```ts\n   * collection\n   *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n   *     { $addFields: { comment: 'big changes' } },\n   *     { $match: { operationType: 'insert' } }\n   *   ])\n   *   .on('change', change => {\n   *     change.comment.startsWith('big');\n   *     change.operationType === 'insert';\n   *     // No need to narrow in code because the generics did that for us!\n   *     expectType<Schema>(change.fullDocument);\n   *   });\n   * ```\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   *\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TLocal - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch(pipeline = [], options = {}) {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n    return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n  }\n  /**\n   * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeUnorderedBulkOp(options) {\n    return new unordered_1.UnorderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n  }\n  /**\n   * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeOrderedBulkOp(options) {\n    return new ordered_1.OrderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n  }\n  /**\n   * An estimated count of matching documents in the db to a filter.\n   *\n   * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n   * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n   * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n   *\n   * @param filter - The filter for the count.\n   * @param options - Optional settings for the command\n   */\n  async count(filter = {}, options = {}) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.fullNamespace, filter, (0, utils_1.resolveOptions)(this, options)));\n  }\n  listSearchIndexes(indexNameOrOptions, options) {\n    options = typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n    const indexName = indexNameOrOptions == null ? null : typeof indexNameOrOptions === 'object' ? null : indexNameOrOptions;\n    return new list_search_indexes_cursor_1.ListSearchIndexesCursor(this, indexName, options);\n  }\n  /**\n   * Creates a single search index for the collection.\n   *\n   * @param description - The index description for the new search index.\n   * @returns A promise that resolves to the name of the new search index.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async createSearchIndex(description) {\n    const [index] = await this.createSearchIndexes([description]);\n    return index;\n  }\n  /**\n   * Creates multiple search indexes for the current collection.\n   *\n   * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n   * @returns A promise that resolves to an array of the newly created search index names.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   * @returns\n   */\n  async createSearchIndexes(descriptions) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new create_1.CreateSearchIndexesOperation(this, descriptions));\n  }\n  /**\n   * Deletes a search index by index name.\n   *\n   * @param name - The name of the search index to be deleted.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async dropSearchIndex(name) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropSearchIndexOperation(this, name));\n  }\n  /**\n   * Updates a search index by replacing the existing index definition with the provided definition.\n   *\n   * @param name - The name of the search index to update.\n   * @param definition - The new search index definition.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async updateSearchIndex(name, definition) {\n    return await (0, execute_operation_1.executeOperation)(this.client, new update_1.UpdateSearchIndexOperation(this, name, definition));\n  }\n}\nexports.Collection = Collection;","map":{"version":3,"names":["bson_1","require","ordered_1","unordered_1","change_stream_1","aggregation_cursor_1","find_cursor_1","list_indexes_cursor_1","list_search_indexes_cursor_1","error_1","count_1","delete_1","distinct_1","estimated_document_count_1","execute_operation_1","find_and_modify_1","indexes_1","insert_1","rename_1","create_1","drop_1","update_1","update_2","read_concern_1","read_preference_1","utils_1","write_concern_1","Collection","constructor","db","name","options","s","namespace","MongoDBCollectionNamespace","databaseName","pkFactory","DEFAULT_PK_FACTORY","readPreference","ReadPreference","fromOptions","bsonOptions","resolveBSONOptions","readConcern","ReadConcern","writeConcern","WriteConcern","client","dbName","collectionName","collection","fullNamespace","toString","hint","collectionHint","v","normalizeHintField","timeoutMS","insertOne","doc","executeOperation","InsertOneOperation","resolveOptions","insertMany","docs","Array","isArray","MongoInvalidArgumentError","acknowledged","w","res","bulkWrite","map","document","insertedCount","insertedIds","err","message","operations","isConnected","topology","autoConnect","bulk","ordered","initializeUnorderedBulkOp","initializeOrderedBulkOp","operation","raw","execute","updateOne","filter","update","UpdateOneOperation","replaceOne","replacement","ReplaceOneOperation","updateMany","UpdateManyOperation","deleteOne","DeleteOneOperation","deleteMany","DeleteManyOperation","rename","newName","RenameOperation","undefined","PRIMARY","drop","dropCollection","findOne","opts","singleBatch","cursor","find","limit","result","next","close","FindCursor","listCollections","nameOnly","toArray","MongoAPIError","isCapped","capped","Boolean","createIndex","indexSpec","indexes","CreateIndexesOperation","fromIndexSpecification","createIndexes","indexSpecs","fromIndexDescriptionArray","maxTimeMS","dropIndex","indexName","DropIndexOperation","primary","dropIndexes","error","MongoOperationTimeoutError","listIndexes","ListIndexesCursor","indexExists","indexNames","allIndexes","Set","every","has","indexInformation","full","estimatedDocumentCount","EstimatedDocumentCountOperation","countDocuments","pipeline","push","$match","skip","$skip","$limit","$group","_id","n","$sum","aggregate","distinct","key","DistinctOperation","object","Object","fromEntries","entries","findOneAndDelete","FindOneAndDeleteOperation","findOneAndReplace","FindOneAndReplaceOperation","findOneAndUpdate","FindOneAndUpdateOperation","AggregationCursor","watch","ChangeStream","UnorderedBulkOperation","OrderedBulkOperation","count","CountOperation","listSearchIndexes","indexNameOrOptions","ListSearchIndexesCursor","createSearchIndex","description","index","createSearchIndexes","descriptions","CreateSearchIndexesOperation","dropSearchIndex","DropSearchIndexOperation","updateSearchIndex","definition","UpdateSearchIndexOperation","exports"],"sources":["C:\\DEVC\\node_modules\\mongodb\\src\\collection.ts"],"sourcesContent":["import { type BSONSerializeOptions, type Document, resolveBSONOptions } from './bson';\nimport type {\n  AnyBulkWriteOperation,\n  BulkOperationBase,\n  BulkWriteOptions,\n  BulkWriteResult\n} from './bulk/common';\nimport { OrderedBulkOperation } from './bulk/ordered';\nimport { UnorderedBulkOperation } from './bulk/unordered';\nimport { ChangeStream, type ChangeStreamDocument, type ChangeStreamOptions } from './change_stream';\nimport { AggregationCursor } from './cursor/aggregation_cursor';\nimport { FindCursor } from './cursor/find_cursor';\nimport { ListIndexesCursor } from './cursor/list_indexes_cursor';\nimport {\n  ListSearchIndexesCursor,\n  type ListSearchIndexesOptions\n} from './cursor/list_search_indexes_cursor';\nimport type { Db } from './db';\nimport { MongoAPIError, MongoInvalidArgumentError, MongoOperationTimeoutError } from './error';\nimport { type ExplainCommandOptions, type ExplainVerbosityLike } from './explain';\nimport type { MongoClient, PkFactory } from './mongo_client';\nimport type {\n  Abortable,\n  Filter,\n  Flatten,\n  OptionalUnlessRequiredId,\n  TODO_NODE_3286,\n  UpdateFilter,\n  WithId,\n  WithoutId\n} from './mongo_types';\nimport type { AggregateOptions } from './operations/aggregate';\nimport { CountOperation, type CountOptions } from './operations/count';\nimport {\n  DeleteManyOperation,\n  DeleteOneOperation,\n  type DeleteOptions,\n  type DeleteResult\n} from './operations/delete';\nimport { DistinctOperation, type DistinctOptions } from './operations/distinct';\nimport { type DropCollectionOptions } from './operations/drop';\nimport {\n  EstimatedDocumentCountOperation,\n  type EstimatedDocumentCountOptions\n} from './operations/estimated_document_count';\nimport { autoConnect, executeOperation } from './operations/execute_operation';\nimport { type FindOneOptions, type FindOptions } from './operations/find';\nimport {\n  FindOneAndDeleteOperation,\n  type FindOneAndDeleteOptions,\n  FindOneAndReplaceOperation,\n  type FindOneAndReplaceOptions,\n  FindOneAndUpdateOperation,\n  type FindOneAndUpdateOptions\n} from './operations/find_and_modify';\nimport {\n  CreateIndexesOperation,\n  type CreateIndexesOptions,\n  type DropIndexesOptions,\n  DropIndexOperation,\n  type IndexDescription,\n  type IndexDescriptionCompact,\n  type IndexDescriptionInfo,\n  type IndexInformationOptions,\n  type IndexSpecification,\n  type ListIndexesOptions\n} from './operations/indexes';\nimport {\n  type InsertManyResult,\n  InsertOneOperation,\n  type InsertOneOptions,\n  type InsertOneResult\n} from './operations/insert';\nimport type { Hint, OperationOptions } from './operations/operation';\nimport { RenameOperation, type RenameOptions } from './operations/rename';\nimport {\n  CreateSearchIndexesOperation,\n  type SearchIndexDescription\n} from './operations/search_indexes/create';\nimport { DropSearchIndexOperation } from './operations/search_indexes/drop';\nimport { UpdateSearchIndexOperation } from './operations/search_indexes/update';\nimport {\n  ReplaceOneOperation,\n  type ReplaceOptions,\n  UpdateManyOperation,\n  UpdateOneOperation,\n  type UpdateOptions,\n  type UpdateResult\n} from './operations/update';\nimport { ReadConcern, type ReadConcernLike } from './read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from './read_preference';\nimport { type Sort } from './sort';\nimport {\n  DEFAULT_PK_FACTORY,\n  MongoDBCollectionNamespace,\n  normalizeHintField,\n  resolveOptions\n} from './utils';\nimport { WriteConcern, type WriteConcernOptions } from './write_concern';\n\n/** @public */\nexport interface ModifyResult<TSchema = Document> {\n  value: WithId<TSchema> | null;\n  lastErrorObject?: Document;\n  ok: 0 | 1;\n}\n\n/** @public */\nexport interface CountDocumentsOptions extends AggregateOptions {\n  /** The number of documents to skip. */\n  skip?: number;\n  /** The maximum amount of documents to consider. */\n  limit?: number;\n}\n\n/** @public */\nexport interface CollectionOptions extends BSONSerializeOptions, WriteConcernOptions {\n  /** Specify a read concern for the collection. (only MongoDB 3.2 or higher supported) */\n  readConcern?: ReadConcernLike;\n  /** The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST). */\n  readPreference?: ReadPreferenceLike;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/** @internal */\nexport interface CollectionPrivate {\n  pkFactory: PkFactory;\n  db: Db;\n  options: any;\n  namespace: MongoDBCollectionNamespace;\n  readPreference?: ReadPreference;\n  bsonOptions: BSONSerializeOptions;\n  collectionHint?: Hint;\n  readConcern?: ReadConcern;\n  writeConcern?: WriteConcern;\n}\n\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nexport class Collection<TSchema extends Document = Document> {\n  /** @internal */\n  s: CollectionPrivate;\n\n  /** @internal */\n  client: MongoClient;\n\n  /**\n   * Get the database object for the collection.\n   */\n  readonly db: Db;\n\n  /**\n   * Create a new Collection instance\n   * @internal\n   */\n  constructor(db: Db, name: string, options?: CollectionOptions) {\n    this.db = db;\n    // Internal state\n    this.s = {\n      db,\n      options,\n      namespace: new MongoDBCollectionNamespace(db.databaseName, name),\n      pkFactory: db.options?.pkFactory ?? DEFAULT_PK_FACTORY,\n      readPreference: ReadPreference.fromOptions(options),\n      bsonOptions: resolveBSONOptions(options, db),\n      readConcern: ReadConcern.fromOptions(options),\n      writeConcern: WriteConcern.fromOptions(options)\n    };\n\n    this.client = db.client;\n  }\n\n  /**\n   * The name of the database this collection belongs to\n   */\n  get dbName(): string {\n    return this.s.namespace.db;\n  }\n\n  /**\n   * The name of this collection\n   */\n  get collectionName(): string {\n    return this.s.namespace.collection;\n  }\n\n  /**\n   * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n   */\n  get namespace(): string {\n    return this.fullNamespace.toString();\n  }\n\n  /**\n   *  @internal\n   *\n   * The `MongoDBNamespace` for the collection.\n   */\n  get fullNamespace(): MongoDBCollectionNamespace {\n    return this.s.namespace;\n  }\n\n  /**\n   * The current readConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readConcern(): ReadConcern | undefined {\n    if (this.s.readConcern == null) {\n      return this.db.readConcern;\n    }\n    return this.s.readConcern;\n  }\n\n  /**\n   * The current readPreference of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readPreference(): ReadPreference | undefined {\n    if (this.s.readPreference == null) {\n      return this.db.readPreference;\n    }\n\n    return this.s.readPreference;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  /**\n   * The current writeConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get writeConcern(): WriteConcern | undefined {\n    if (this.s.writeConcern == null) {\n      return this.db.writeConcern;\n    }\n    return this.s.writeConcern;\n  }\n\n  /** The current index hint for the collection */\n  get hint(): Hint | undefined {\n    return this.s.collectionHint;\n  }\n\n  set hint(v: Hint | undefined) {\n    this.s.collectionHint = normalizeHintField(v);\n  }\n\n  public get timeoutMS(): number | undefined {\n    return this.s.options.timeoutMS;\n  }\n\n  /**\n   * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param doc - The document to insert\n   * @param options - Optional settings for the command\n   */\n  async insertOne(\n    doc: OptionalUnlessRequiredId<TSchema>,\n    options?: InsertOneOptions\n  ): Promise<InsertOneResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new InsertOneOperation(\n        this as TODO_NODE_3286,\n        doc,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param docs - The documents to insert\n   * @param options - Optional settings for the command\n   */\n  async insertMany(\n    docs: ReadonlyArray<OptionalUnlessRequiredId<TSchema>>,\n    options?: BulkWriteOptions\n  ): Promise<InsertManyResult<TSchema>> {\n    if (!Array.isArray(docs)) {\n      throw new MongoInvalidArgumentError('Argument \"docs\" must be an array of documents');\n    }\n    options = resolveOptions(this, options ?? {});\n\n    const acknowledged = WriteConcern.fromOptions(options)?.w !== 0;\n\n    try {\n      const res = await this.bulkWrite(\n        docs.map(doc => ({ insertOne: { document: doc } })),\n        options\n      );\n      return {\n        acknowledged,\n        insertedCount: res.insertedCount,\n        insertedIds: res.insertedIds\n      };\n    } catch (err) {\n      if (err && err.message === 'Operation must be an object with an operation key') {\n        throw new MongoInvalidArgumentError(\n          'Collection.insertMany() cannot be called with an array that has null/undefined values'\n        );\n      }\n      throw err;\n    }\n  }\n\n  /**\n   * Perform a bulkWrite operation without a fluent API\n   *\n   * Legal operation types are\n   * - `insertOne`\n   * - `replaceOne`\n   * - `updateOne`\n   * - `updateMany`\n   * - `deleteOne`\n   * - `deleteMany`\n   *\n   * If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param operations - Bulk operations to perform\n   * @param options - Optional settings for the command\n   * @throws MongoDriverError if operations is not an array\n   */\n  async bulkWrite(\n    operations: ReadonlyArray<AnyBulkWriteOperation<TSchema>>,\n    options?: BulkWriteOptions\n  ): Promise<BulkWriteResult> {\n    if (!Array.isArray(operations)) {\n      throw new MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n    }\n\n    options = resolveOptions(this, options ?? {});\n\n    // TODO(NODE-7071): remove once the client doesn't need to be connected to construct\n    // bulk operations\n    const isConnected = this.client.topology != null;\n    if (!isConnected) {\n      await autoConnect(this.client);\n    }\n\n    // Create the bulk operation\n    const bulk: BulkOperationBase =\n      options.ordered === false\n        ? this.initializeUnorderedBulkOp(options)\n        : this.initializeOrderedBulkOp(options);\n\n    // for each op go through and add to the bulk\n    for (const operation of operations) {\n      bulk.raw(operation);\n    }\n\n    // Execute the bulk\n    return await bulk.execute({ ...options });\n  }\n\n  /**\n   * Update a single document in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateOne(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: UpdateOptions & { sort?: Sort }\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new UpdateOneOperation(this.s.namespace, filter, update, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Replace a document in a collection with another document\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async replaceOne(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options?: ReplaceOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new ReplaceOneOperation(this.s.namespace, filter, replacement, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Update multiple documents in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateMany(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: UpdateOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new UpdateManyOperation(this.s.namespace, filter, update, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Delete a document from a collection\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteOne(\n    filter: Filter<TSchema> = {},\n    options: DeleteOptions = {}\n  ): Promise<DeleteResult> {\n    return await executeOperation(\n      this.client,\n      new DeleteOneOperation(this.s.namespace, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Delete multiple documents from a collection\n   *\n   * @param filter - The filter used to select the documents to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteMany(\n    filter: Filter<TSchema> = {},\n    options: DeleteOptions = {}\n  ): Promise<DeleteResult> {\n    return await executeOperation(\n      this.client,\n      new DeleteManyOperation(this.s.namespace, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Rename the collection.\n   *\n   * @remarks\n   * This operation does not inherit options from the Db or MongoClient.\n   *\n   * @param newName - New name of of the collection.\n   * @param options - Optional settings for the command\n   */\n  async rename(newName: string, options?: RenameOptions): Promise<Collection> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RenameOperation(\n        this as TODO_NODE_3286,\n        newName,\n        resolveOptions(undefined, {\n          ...options,\n          readPreference: ReadPreference.PRIMARY\n        })\n      )\n    );\n  }\n\n  /**\n   * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async drop(options?: DropCollectionOptions): Promise<boolean> {\n    return await this.db.dropCollection(this.collectionName, options);\n  }\n\n  /**\n   * Fetches the first document that matches the filter\n   *\n   * @param filter - Query for find Operation\n   * @param options - Optional settings for the command\n   */\n  async findOne(): Promise<WithId<TSchema> | null>;\n  async findOne(filter: Filter<TSchema>): Promise<WithId<TSchema> | null>;\n  async findOne(\n    filter: Filter<TSchema>,\n    options: Omit<FindOneOptions, 'timeoutMode'> & Abortable\n  ): Promise<WithId<TSchema> | null>;\n\n  // allow an override of the schema.\n  async findOne<T = TSchema>(): Promise<T | null>;\n  async findOne<T = TSchema>(filter: Filter<TSchema>): Promise<T | null>;\n  async findOne<T = TSchema>(\n    filter: Filter<TSchema>,\n    options?: Omit<FindOneOptions, 'timeoutMode'> & Abortable\n  ): Promise<T | null>;\n\n  async findOne(\n    filter: Filter<TSchema> = {},\n    options: Omit<FindOneOptions, 'timeoutMode'> & Abortable = {}\n  ): Promise<WithId<TSchema> | null> {\n    // Explicitly set the limit to 1 and singleBatch to true for all commands, per the spec.\n    // noCursorTimeout must be unset as well as batchSize.\n    // See: https://github.com/mongodb/specifications/blob/master/source/crud/crud.md#findone-api-details\n    const { ...opts } = options;\n    opts.singleBatch = true;\n    const cursor = this.find(filter, opts).limit(1);\n    const result = await cursor.next();\n    await cursor.close();\n    return result;\n  }\n\n  /**\n   * Creates a cursor for a filter that can be used to iterate over results from MongoDB\n   *\n   * @param filter - The filter predicate. If unspecified, then all documents in the collection will match the predicate\n   */\n  find(): FindCursor<WithId<TSchema>>;\n  find(filter: Filter<TSchema>, options?: FindOptions & Abortable): FindCursor<WithId<TSchema>>;\n  find<T extends Document>(\n    filter: Filter<TSchema>,\n    options?: FindOptions & Abortable\n  ): FindCursor<T>;\n  find(\n    filter: Filter<TSchema> = {},\n    options: FindOptions & Abortable = {}\n  ): FindCursor<WithId<TSchema>> {\n    return new FindCursor<WithId<TSchema>>(\n      this.client,\n      this.s.namespace,\n      filter,\n      resolveOptions(this, options)\n    );\n  }\n\n  /**\n   * Returns the options of the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async options(options?: OperationOptions): Promise<Document> {\n    options = resolveOptions(this, options);\n    const [collection] = await this.db\n      .listCollections({ name: this.collectionName }, { ...options, nameOnly: false })\n      .toArray();\n\n    if (collection == null || collection.options == null) {\n      throw new MongoAPIError(`collection ${this.namespace} not found`);\n    }\n\n    return collection.options;\n  }\n\n  /**\n   * Returns if the collection is a capped collection\n   *\n   * @param options - Optional settings for the command\n   */\n  async isCapped(options?: OperationOptions): Promise<boolean> {\n    const { capped } = await this.options(options);\n    return Boolean(capped);\n  }\n\n  /**\n   * Creates an index on the db and collection collection.\n   *\n   * @param indexSpec - The field name or index specification to create an index for\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   *\n   * await collection.createIndex({ a: 1, b: -1 });\n   *\n   * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n   * await collection.createIndex([ [c, 1], [d, -1] ]);\n   *\n   * // Equivalent to { e: 1 }\n   * await collection.createIndex('e');\n   *\n   * // Equivalent to { f: 1, g: 1 }\n   * await collection.createIndex(['f', 'g'])\n   *\n   * // Equivalent to { h: 1, i: -1 }\n   * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n   *\n   * // Equivalent to { j: 1, k: -1, l: 2d }\n   * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n   * ```\n   */\n  async createIndex(\n    indexSpec: IndexSpecification,\n    options?: CreateIndexesOptions\n  ): Promise<string> {\n    const indexes = await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexSpecification(\n        this,\n        this.collectionName,\n        indexSpec,\n        resolveOptions(this, options)\n      )\n    );\n\n    return indexes[0];\n  }\n\n  /**\n   * Creates multiple indexes in the collection, this method is only supported for\n   * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n   * error.\n   *\n   * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n   * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n   *\n   * @param indexSpecs - An array of index specifications to be created\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   * await collection.createIndexes([\n   *   // Simple index on field fizz\n   *   {\n   *     key: { fizz: 1 },\n   *   }\n   *   // wildcard index\n   *   {\n   *     key: { '$**': 1 }\n   *   },\n   *   // named index on darmok and jalad\n   *   {\n   *     key: { darmok: 1, jalad: -1 }\n   *     name: 'tanagra'\n   *   }\n   * ]);\n   * ```\n   */\n  async createIndexes(\n    indexSpecs: IndexDescription[],\n    options?: CreateIndexesOptions\n  ): Promise<string[]> {\n    return await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexDescriptionArray(\n        this,\n        this.collectionName,\n        indexSpecs,\n        resolveOptions(this, { ...options, maxTimeMS: undefined })\n      )\n    );\n  }\n\n  /**\n   * Drops an index from this collection.\n   *\n   * @param indexName - Name of the index to drop.\n   * @param options - Optional settings for the command\n   */\n  async dropIndex(indexName: string, options?: DropIndexesOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new DropIndexOperation(this as TODO_NODE_3286, indexName, {\n        ...resolveOptions(this, options),\n        readPreference: ReadPreference.primary\n      })\n    );\n  }\n\n  /**\n   * Drops all indexes from this collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async dropIndexes(options?: DropIndexesOptions): Promise<boolean> {\n    try {\n      await executeOperation(\n        this.client,\n        new DropIndexOperation(this as TODO_NODE_3286, '*', resolveOptions(this, options))\n      );\n      return true;\n    } catch (error) {\n      // TODO(NODE-6517): Driver should only filter for namespace not found error. Other errors should be thrown.\n      if (error instanceof MongoOperationTimeoutError) throw error;\n      return false;\n    }\n  }\n\n  /**\n   * Get the list of all indexes information for the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  listIndexes(options?: ListIndexesOptions): ListIndexesCursor {\n    return new ListIndexesCursor(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * Checks if one or more indexes exist on the collection, fails on first non-existing index\n   *\n   * @param indexes - One or more index names to check.\n   * @param options - Optional settings for the command\n   */\n  async indexExists(indexes: string | string[], options?: ListIndexesOptions): Promise<boolean> {\n    const indexNames: string[] = Array.isArray(indexes) ? indexes : [indexes];\n    const allIndexes: Set<string> = new Set(\n      await this.listIndexes(options)\n        .map(({ name }) => name)\n        .toArray()\n    );\n    return indexNames.every(name => allIndexes.has(name));\n  }\n\n  /**\n   * Retrieves this collections index info.\n   *\n   * @param options - Optional settings for the command\n   */\n  indexInformation(\n    options: IndexInformationOptions & { full: true }\n  ): Promise<IndexDescriptionInfo[]>;\n  indexInformation(\n    options: IndexInformationOptions & { full?: false }\n  ): Promise<IndexDescriptionCompact>;\n  indexInformation(\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexInformation(): Promise<IndexDescriptionCompact>;\n  async indexInformation(\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    return await this.indexes({\n      ...options,\n      full: options?.full ?? false\n    });\n  }\n\n  /**\n   * Gets an estimate of the count of documents in a collection using collection metadata.\n   * This will always run a count command on all server versions.\n   *\n   * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n   * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n   * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n   * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n   * encountering errors.\n   *\n   * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n   * @param options - Optional settings for the command\n   */\n  async estimatedDocumentCount(options?: EstimatedDocumentCountOptions): Promise<number> {\n    return await executeOperation(\n      this.client,\n      new EstimatedDocumentCountOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Gets the number of documents matching the filter.\n   * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * Due to countDocuments using the $match aggregation pipeline stage, certain query operators cannot be used in countDocuments. This includes the $where and $near query operators, among others. Details can be found in the documentation for the $match aggregation pipeline stage.\n   *\n   * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n   * the following query operators must be replaced:\n   *\n   * | Operator | Replacement |\n   * | -------- | ----------- |\n   * | `$where`   | [`$expr`][1] |\n   * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n   * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n   *\n   * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   *\n   * @param filter - The filter for the count\n   * @param options - Optional settings for the command\n   *\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   */\n  async countDocuments(\n    filter: Filter<TSchema> = {},\n    options: CountDocumentsOptions & Abortable = {}\n  ): Promise<number> {\n    const pipeline = [];\n    pipeline.push({ $match: filter });\n\n    if (typeof options.skip === 'number') {\n      pipeline.push({ $skip: options.skip });\n    }\n\n    if (typeof options.limit === 'number') {\n      pipeline.push({ $limit: options.limit });\n    }\n\n    pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });\n\n    const cursor = this.aggregate<{ n: number }>(pipeline, options);\n    const doc = await cursor.next();\n    await cursor.close();\n    return doc?.n ?? 0;\n  }\n\n  /**\n   * The distinct command returns a list of distinct values for the given key across a collection.\n   *\n   * @param key - Field of the document to find distinct values for\n   * @param filter - The filter for filtering the set of documents to which we apply the distinct filter.\n   * @param options - Optional settings for the command\n   */\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>,\n    options: DistinctOptions\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>,\n    options: DistinctOptions & { explain: ExplainVerbosityLike | ExplainCommandOptions }\n  ): Promise<Document>;\n\n  // Embedded documents overload\n  distinct(key: string): Promise<any[]>;\n  distinct(key: string, filter: Filter<TSchema>): Promise<any[]>;\n  distinct(key: string, filter: Filter<TSchema>, options: DistinctOptions): Promise<any[]>;\n\n  async distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema> = {},\n    options: DistinctOptions = {}\n  ): Promise<any[]> {\n    return await executeOperation(\n      this.client,\n      new DistinctOperation(\n        this as TODO_NODE_3286,\n        key as TODO_NODE_3286,\n        filter,\n        resolveOptions(this, options)\n      )\n    );\n  }\n\n  /**\n   * Retrieve all the indexes on the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  indexes(options: IndexInformationOptions & { full?: true }): Promise<IndexDescriptionInfo[]>;\n  indexes(options: IndexInformationOptions & { full: false }): Promise<IndexDescriptionCompact>;\n  indexes(\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexes(options?: ListIndexesOptions): Promise<IndexDescriptionInfo[]>;\n  async indexes(\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    const indexes: IndexDescriptionInfo[] = await this.listIndexes(options).toArray();\n    const full = options?.full ?? true;\n    if (full) {\n      return indexes;\n    }\n\n    const object: IndexDescriptionCompact = Object.fromEntries(\n      indexes.map(({ name, key }) => [name, Object.entries(key)])\n    );\n\n    return object;\n  }\n\n  /**\n   * Find a document and delete it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(filter: Filter<TSchema>): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options?: FindOneAndDeleteOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndDeleteOperation(\n        this as TODO_NODE_3286,\n        filter,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Find a document and replace it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options?: FindOneAndReplaceOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndReplaceOperation(\n        this as TODO_NODE_3286,\n        filter,\n        replacement,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Find a document and update it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline consisting of the following stages:\n   *   - $addFields and its alias $set\n   *   - $project and its alias $unset\n   *   - $replaceRoot and its alias $replaceWith.\n   * See the [findAndModify command documentation](https://www.mongodb.com/docs/manual/reference/command/findAndModify) for details.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[]\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: FindOneAndUpdateOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndUpdateOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n   *\n   * @param pipeline - An array of aggregation pipelines to execute\n   * @param options - Optional settings for the command\n   */\n  aggregate<T extends Document = Document>(\n    pipeline: Document[] = [],\n    options?: AggregateOptions & Abortable\n  ): AggregationCursor<T> {\n    if (!Array.isArray(pipeline)) {\n      throw new MongoInvalidArgumentError(\n        'Argument \"pipeline\" must be an array of aggregation stages'\n      );\n    }\n\n    return new AggregationCursor(\n      this.client,\n      this.s.namespace,\n      pipeline,\n      resolveOptions(this, options)\n    );\n  }\n\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to override the schema that may be defined for this specific collection\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   * @example\n   * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n   * ```ts\n   * collection.watch<{ _id: number }>()\n   *   .on('change', change => console.log(change._id.toFixed(4)));\n   * ```\n   *\n   * @example\n   * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n   * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n   * No need start from scratch on the ChangeStreamInsertDocument type!\n   * By using an intersection we can save time and ensure defaults remain the same type!\n   * ```ts\n   * collection\n   *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n   *     { $addFields: { comment: 'big changes' } },\n   *     { $match: { operationType: 'insert' } }\n   *   ])\n   *   .on('change', change => {\n   *     change.comment.startsWith('big');\n   *     change.operationType === 'insert';\n   *     // No need to narrow in code because the generics did that for us!\n   *     expectType<Schema>(change.fullDocument);\n   *   });\n   * ```\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   *\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TLocal - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch<TLocal extends Document = TSchema, TChange extends Document = ChangeStreamDocument<TLocal>>(\n    pipeline: Document[] = [],\n    options: ChangeStreamOptions = {}\n  ): ChangeStream<TLocal, TChange> {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n\n    return new ChangeStream<TLocal, TChange>(this, pipeline, resolveOptions(this, options));\n  }\n\n  /**\n   * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeUnorderedBulkOp(options?: BulkWriteOptions): UnorderedBulkOperation {\n    return new UnorderedBulkOperation(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeOrderedBulkOp(options?: BulkWriteOptions): OrderedBulkOperation {\n    return new OrderedBulkOperation(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * An estimated count of matching documents in the db to a filter.\n   *\n   * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n   * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n   * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n   *\n   * @param filter - The filter for the count.\n   * @param options - Optional settings for the command\n   */\n  async count(filter: Filter<TSchema> = {}, options: CountOptions = {}): Promise<number> {\n    return await executeOperation(\n      this.client,\n      new CountOperation(this.fullNamespace, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Returns all search indexes for the current collection.\n   *\n   * @param options - The options for the list indexes operation.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  listSearchIndexes(options?: ListSearchIndexesOptions): ListSearchIndexesCursor;\n  /**\n   * Returns all search indexes for the current collection.\n   *\n   * @param name - The name of the index to search for.  Only indexes with matching index names will be returned.\n   * @param options - The options for the list indexes operation.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  listSearchIndexes(name: string, options?: ListSearchIndexesOptions): ListSearchIndexesCursor;\n  listSearchIndexes(\n    indexNameOrOptions?: string | ListSearchIndexesOptions,\n    options?: ListSearchIndexesOptions\n  ): ListSearchIndexesCursor {\n    options =\n      typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n\n    const indexName =\n      indexNameOrOptions == null\n        ? null\n        : typeof indexNameOrOptions === 'object'\n          ? null\n          : indexNameOrOptions;\n\n    return new ListSearchIndexesCursor(this as TODO_NODE_3286, indexName, options);\n  }\n\n  /**\n   * Creates a single search index for the collection.\n   *\n   * @param description - The index description for the new search index.\n   * @returns A promise that resolves to the name of the new search index.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async createSearchIndex(description: SearchIndexDescription): Promise<string> {\n    const [index] = await this.createSearchIndexes([description]);\n    return index;\n  }\n\n  /**\n   * Creates multiple search indexes for the current collection.\n   *\n   * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n   * @returns A promise that resolves to an array of the newly created search index names.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   * @returns\n   */\n  async createSearchIndexes(descriptions: SearchIndexDescription[]): Promise<string[]> {\n    return await executeOperation(\n      this.client,\n      new CreateSearchIndexesOperation(this as TODO_NODE_3286, descriptions)\n    );\n  }\n\n  /**\n   * Deletes a search index by index name.\n   *\n   * @param name - The name of the search index to be deleted.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async dropSearchIndex(name: string): Promise<void> {\n    return await executeOperation(\n      this.client,\n      new DropSearchIndexOperation(this as TODO_NODE_3286, name)\n    );\n  }\n\n  /**\n   * Updates a search index by replacing the existing index definition with the provided definition.\n   *\n   * @param name - The name of the search index to update.\n   * @param definition - The new search index definition.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async updateSearchIndex(name: string, definition: Document): Promise<void> {\n    return await executeOperation(\n      this.client,\n      new UpdateSearchIndexOperation(this as TODO_NODE_3286, name, definition)\n    );\n  }\n}\n"],"mappings":";;;;;;AAAA,MAAAA,MAAA,GAAAC,OAAA;AAOA,MAAAC,SAAA,GAAAD,OAAA;AACA,MAAAE,WAAA,GAAAF,OAAA;AACA,MAAAG,eAAA,GAAAH,OAAA;AACA,MAAAI,oBAAA,GAAAJ,OAAA;AACA,MAAAK,aAAA,GAAAL,OAAA;AACA,MAAAM,qBAAA,GAAAN,OAAA;AACA,MAAAO,4BAAA,GAAAP,OAAA;AAKA,MAAAQ,OAAA,GAAAR,OAAA;AAcA,MAAAS,OAAA,GAAAT,OAAA;AACA,MAAAU,QAAA,GAAAV,OAAA;AAMA,MAAAW,UAAA,GAAAX,OAAA;AAEA,MAAAY,0BAAA,GAAAZ,OAAA;AAIA,MAAAa,mBAAA,GAAAb,OAAA;AAEA,MAAAc,iBAAA,GAAAd,OAAA;AAQA,MAAAe,SAAA,GAAAf,OAAA;AAYA,MAAAgB,QAAA,GAAAhB,OAAA;AAOA,MAAAiB,QAAA,GAAAjB,OAAA;AACA,MAAAkB,QAAA,GAAAlB,OAAA;AAIA,MAAAmB,MAAA,GAAAnB,OAAA;AACA,MAAAoB,QAAA,GAAApB,OAAA;AACA,MAAAqB,QAAA,GAAArB,OAAA;AAQA,MAAAsB,cAAA,GAAAtB,OAAA;AACA,MAAAuB,iBAAA,GAAAvB,OAAA;AAEA,MAAAwB,OAAA,GAAAxB,OAAA;AAMA,MAAAyB,eAAA,GAAAzB,OAAA;AA2CA;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BA,MAAa0B,UAAU;EAYrB;;;;EAIAC,YAAYC,EAAM,EAAEC,IAAY,EAAEC,OAA2B;IAC3D,IAAI,CAACF,EAAE,GAAGA,EAAE;IACZ;IACA,IAAI,CAACG,CAAC,GAAG;MACPH,EAAE;MACFE,OAAO;MACPE,SAAS,EAAE,IAAIR,OAAA,CAAAS,0BAA0B,CAACL,EAAE,CAACM,YAAY,EAAEL,IAAI,CAAC;MAChEM,SAAS,EAAEP,EAAE,CAACE,OAAO,EAAEK,SAAS,IAAIX,OAAA,CAAAY,kBAAkB;MACtDC,cAAc,EAAEd,iBAAA,CAAAe,cAAc,CAACC,WAAW,CAACT,OAAO,CAAC;MACnDU,WAAW,EAAE,IAAAzC,MAAA,CAAA0C,kBAAkB,EAACX,OAAO,EAAEF,EAAE,CAAC;MAC5Cc,WAAW,EAAEpB,cAAA,CAAAqB,WAAW,CAACJ,WAAW,CAACT,OAAO,CAAC;MAC7Cc,YAAY,EAAEnB,eAAA,CAAAoB,YAAY,CAACN,WAAW,CAACT,OAAO;KAC/C;IAED,IAAI,CAACgB,MAAM,GAAGlB,EAAE,CAACkB,MAAM;EACzB;EAEA;;;EAGA,IAAIC,MAAMA,CAAA;IACR,OAAO,IAAI,CAAChB,CAAC,CAACC,SAAS,CAACJ,EAAE;EAC5B;EAEA;;;EAGA,IAAIoB,cAAcA,CAAA;IAChB,OAAO,IAAI,CAACjB,CAAC,CAACC,SAAS,CAACiB,UAAU;EACpC;EAEA;;;EAGA,IAAIjB,SAASA,CAAA;IACX,OAAO,IAAI,CAACkB,aAAa,CAACC,QAAQ,EAAE;EACtC;EAEA;;;;;EAKA,IAAID,aAAaA,CAAA;IACf,OAAO,IAAI,CAACnB,CAAC,CAACC,SAAS;EACzB;EAEA;;;;EAIA,IAAIU,WAAWA,CAAA;IACb,IAAI,IAAI,CAACX,CAAC,CAACW,WAAW,IAAI,IAAI,EAAE;MAC9B,OAAO,IAAI,CAACd,EAAE,CAACc,WAAW;IAC5B;IACA,OAAO,IAAI,CAACX,CAAC,CAACW,WAAW;EAC3B;EAEA;;;;EAIA,IAAIL,cAAcA,CAAA;IAChB,IAAI,IAAI,CAACN,CAAC,CAACM,cAAc,IAAI,IAAI,EAAE;MACjC,OAAO,IAAI,CAACT,EAAE,CAACS,cAAc;IAC/B;IAEA,OAAO,IAAI,CAACN,CAAC,CAACM,cAAc;EAC9B;EAEA,IAAIG,WAAWA,CAAA;IACb,OAAO,IAAI,CAACT,CAAC,CAACS,WAAW;EAC3B;EAEA;;;;EAIA,IAAII,YAAYA,CAAA;IACd,IAAI,IAAI,CAACb,CAAC,CAACa,YAAY,IAAI,IAAI,EAAE;MAC/B,OAAO,IAAI,CAAChB,EAAE,CAACgB,YAAY;IAC7B;IACA,OAAO,IAAI,CAACb,CAAC,CAACa,YAAY;EAC5B;EAEA;EACA,IAAIQ,IAAIA,CAAA;IACN,OAAO,IAAI,CAACrB,CAAC,CAACsB,cAAc;EAC9B;EAEA,IAAID,IAAIA,CAACE,CAAmB;IAC1B,IAAI,CAACvB,CAAC,CAACsB,cAAc,GAAG,IAAA7B,OAAA,CAAA+B,kBAAkB,EAACD,CAAC,CAAC;EAC/C;EAEA,IAAWE,SAASA,CAAA;IAClB,OAAO,IAAI,CAACzB,CAAC,CAACD,OAAO,CAAC0B,SAAS;EACjC;EAEA;;;;;;;;EAQA,MAAMC,SAASA,CACbC,GAAsC,EACtC5B,OAA0B;IAE1B,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAI9B,QAAA,CAAA4C,kBAAkB,CACpB,IAAsB,EACtBF,GAAG,EACH,IAAAlC,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CACZ,CACpB;EACH;EAEA;;;;;;;;EAQA,MAAMgC,UAAUA,CACdC,IAAsD,EACtDjC,OAA0B;IAE1B,IAAI,CAACkC,KAAK,CAACC,OAAO,CAACF,IAAI,CAAC,EAAE;MACxB,MAAM,IAAIvD,OAAA,CAAA0D,yBAAyB,CAAC,+CAA+C,CAAC;IACtF;IACApC,OAAO,GAAG,IAAAN,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,IAAI,EAAE,CAAC;IAE7C,MAAMqC,YAAY,GAAG1C,eAAA,CAAAoB,YAAY,CAACN,WAAW,CAACT,OAAO,CAAC,EAAEsC,CAAC,KAAK,CAAC;IAE/D,IAAI;MACF,MAAMC,GAAG,GAAG,MAAM,IAAI,CAACC,SAAS,CAC9BP,IAAI,CAACQ,GAAG,CAACb,GAAG,KAAK;QAAED,SAAS,EAAE;UAAEe,QAAQ,EAAEd;QAAG;MAAE,CAAE,CAAC,CAAC,EACnD5B,OAAO,CACR;MACD,OAAO;QACLqC,YAAY;QACZM,aAAa,EAAEJ,GAAG,CAACI,aAAa;QAChCC,WAAW,EAAEL,GAAG,CAACK;OAClB;IACH,CAAC,CAAC,OAAOC,GAAG,EAAE;MACZ,IAAIA,GAAG,IAAIA,GAAG,CAACC,OAAO,KAAK,mDAAmD,EAAE;QAC9E,MAAM,IAAIpE,OAAA,CAAA0D,yBAAyB,CACjC,uFAAuF,CACxF;MACH;MACA,MAAMS,GAAG;IACX;EACF;EAEA;;;;;;;;;;;;;;;;;;;EAmBA,MAAML,SAASA,CACbO,UAAyD,EACzD/C,OAA0B;IAE1B,IAAI,CAACkC,KAAK,CAACC,OAAO,CAACY,UAAU,CAAC,EAAE;MAC9B,MAAM,IAAIrE,OAAA,CAAA0D,yBAAyB,CAAC,qDAAqD,CAAC;IAC5F;IAEApC,OAAO,GAAG,IAAAN,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,IAAI,EAAE,CAAC;IAE7C;IACA;IACA,MAAMgD,WAAW,GAAG,IAAI,CAAChC,MAAM,CAACiC,QAAQ,IAAI,IAAI;IAChD,IAAI,CAACD,WAAW,EAAE;MAChB,MAAM,IAAAjE,mBAAA,CAAAmE,WAAW,EAAC,IAAI,CAAClC,MAAM,CAAC;IAChC;IAEA;IACA,MAAMmC,IAAI,GACRnD,OAAO,CAACoD,OAAO,KAAK,KAAK,GACrB,IAAI,CAACC,yBAAyB,CAACrD,OAAO,CAAC,GACvC,IAAI,CAACsD,uBAAuB,CAACtD,OAAO,CAAC;IAE3C;IACA,KAAK,MAAMuD,SAAS,IAAIR,UAAU,EAAE;MAClCI,IAAI,CAACK,GAAG,CAACD,SAAS,CAAC;IACrB;IAEA;IACA,OAAO,MAAMJ,IAAI,CAACM,OAAO,CAAC;MAAE,GAAGzD;IAAO,CAAE,CAAC;EAC3C;EAEA;;;;;;;;;;;EAWA,MAAM0D,SAASA,CACbC,MAAuB,EACvBC,MAA0C,EAC1C5D,OAAyC;IAEzC,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIzB,QAAA,CAAAsE,kBAAkB,CAAC,IAAI,CAAC5D,CAAC,CAACC,SAAS,EAAEyD,MAAM,EAAEC,MAAM,EAAE,IAAAlE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CACxF;EACH;EAEA;;;;;;;EAOA,MAAM8D,UAAUA,CACdH,MAAuB,EACvBI,WAA+B,EAC/B/D,OAAwB;IAExB,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIzB,QAAA,CAAAyE,mBAAmB,CAAC,IAAI,CAAC/D,CAAC,CAACC,SAAS,EAAEyD,MAAM,EAAEI,WAAW,EAAE,IAAArE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CAC9F;EACH;EAEA;;;;;;;;;;;EAWA,MAAMiE,UAAUA,CACdN,MAAuB,EACvBC,MAA0C,EAC1C5D,OAAuB;IAEvB,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIzB,QAAA,CAAA2E,mBAAmB,CAAC,IAAI,CAACjE,CAAC,CAACC,SAAS,EAAEyD,MAAM,EAAEC,MAAM,EAAE,IAAAlE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CACzF;EACH;EAEA;;;;;;EAMA,MAAMmE,SAASA,CACbR,MAAA,GAA0B,EAAE,EAC5B3D,OAAA,GAAyB,EAAE;IAE3B,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIpC,QAAA,CAAAwF,kBAAkB,CAAC,IAAI,CAACnE,CAAC,CAACC,SAAS,EAAEyD,MAAM,EAAE,IAAAjE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CAChF;EACH;EAEA;;;;;;EAMA,MAAMqE,UAAUA,CACdV,MAAA,GAA0B,EAAE,EAC5B3D,OAAA,GAAyB,EAAE;IAE3B,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIpC,QAAA,CAAA0F,mBAAmB,CAAC,IAAI,CAACrE,CAAC,CAACC,SAAS,EAAEyD,MAAM,EAAE,IAAAjE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CACjF;EACH;EAEA;;;;;;;;;EASA,MAAMuE,MAAMA,CAACC,OAAe,EAAExE,OAAuB;IACnD;IACA,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAI7B,QAAA,CAAAsF,eAAe,CACjB,IAAsB,EACtBD,OAAO,EACP,IAAA9E,OAAA,CAAAqC,cAAc,EAAC2C,SAAS,EAAE;MACxB,GAAG1E,OAAO;MACVO,cAAc,EAAEd,iBAAA,CAAAe,cAAc,CAACmE;KAChC,CAAC,CACH,CACF;EACH;EAEA;;;;;EAKA,MAAMC,IAAIA,CAAC5E,OAA+B;IACxC,OAAO,MAAM,IAAI,CAACF,EAAE,CAAC+E,cAAc,CAAC,IAAI,CAAC3D,cAAc,EAAElB,OAAO,CAAC;EACnE;EAuBA,MAAM8E,OAAOA,CACXnB,MAAA,GAA0B,EAAE,EAC5B3D,OAAA,GAA2D,EAAE;IAE7D;IACA;IACA;IACA,MAAM;MAAE,GAAG+E;IAAI,CAAE,GAAG/E,OAAO;IAC3B+E,IAAI,CAACC,WAAW,GAAG,IAAI;IACvB,MAAMC,MAAM,GAAG,IAAI,CAACC,IAAI,CAACvB,MAAM,EAAEoB,IAAI,CAAC,CAACI,KAAK,CAAC,CAAC,CAAC;IAC/C,MAAMC,MAAM,GAAG,MAAMH,MAAM,CAACI,IAAI,EAAE;IAClC,MAAMJ,MAAM,CAACK,KAAK,EAAE;IACpB,OAAOF,MAAM;EACf;EAaAF,IAAIA,CACFvB,MAAA,GAA0B,EAAE,EAC5B3D,OAAA,GAAmC,EAAE;IAErC,OAAO,IAAIzB,aAAA,CAAAgH,UAAU,CACnB,IAAI,CAACvE,MAAM,EACX,IAAI,CAACf,CAAC,CAACC,SAAS,EAChByD,MAAM,EACN,IAAAjE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAC9B;EACH;EAEA;;;;;EAKA,MAAMA,OAAOA,CAACA,OAA0B;IACtCA,OAAO,GAAG,IAAAN,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC;IACvC,MAAM,CAACmB,UAAU,CAAC,GAAG,MAAM,IAAI,CAACrB,EAAE,CAC/B0F,eAAe,CAAC;MAAEzF,IAAI,EAAE,IAAI,CAACmB;IAAc,CAAE,EAAE;MAAE,GAAGlB,OAAO;MAAEyF,QAAQ,EAAE;IAAK,CAAE,CAAC,CAC/EC,OAAO,EAAE;IAEZ,IAAIvE,UAAU,IAAI,IAAI,IAAIA,UAAU,CAACnB,OAAO,IAAI,IAAI,EAAE;MACpD,MAAM,IAAItB,OAAA,CAAAiH,aAAa,CAAC,cAAc,IAAI,CAACzF,SAAS,YAAY,CAAC;IACnE;IAEA,OAAOiB,UAAU,CAACnB,OAAO;EAC3B;EAEA;;;;;EAKA,MAAM4F,QAAQA,CAAC5F,OAA0B;IACvC,MAAM;MAAE6F;IAAM,CAAE,GAAG,MAAM,IAAI,CAAC7F,OAAO,CAACA,OAAO,CAAC;IAC9C,OAAO8F,OAAO,CAACD,MAAM,CAAC;EACxB;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BA,MAAME,WAAWA,CACfC,SAA6B,EAC7BhG,OAA8B;IAE9B,MAAMiG,OAAO,GAAG,MAAM,IAAAlH,mBAAA,CAAA8C,gBAAgB,EACpC,IAAI,CAACb,MAAM,EACX/B,SAAA,CAAAiH,sBAAsB,CAACC,sBAAsB,CAC3C,IAAI,EACJ,IAAI,CAACjF,cAAc,EACnB8E,SAAS,EACT,IAAAtG,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAC9B,CACF;IAED,OAAOiG,OAAO,CAAC,CAAC,CAAC;EACnB;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA+BA,MAAMG,aAAaA,CACjBC,UAA8B,EAC9BrG,OAA8B;IAE9B,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX/B,SAAA,CAAAiH,sBAAsB,CAACI,yBAAyB,CAC9C,IAAI,EACJ,IAAI,CAACpF,cAAc,EACnBmF,UAAU,EACV,IAAA3G,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE;MAAE,GAAG/B,OAAO;MAAEuG,SAAS,EAAE7B;IAAS,CAAE,CAAC,CAC3D,CACF;EACH;EAEA;;;;;;EAMA,MAAM8B,SAASA,CAACC,SAAiB,EAAEzG,OAA4B;IAC7D,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAI/B,SAAA,CAAAyH,kBAAkB,CAAC,IAAsB,EAAED,SAAS,EAAE;MACxD,GAAG,IAAA/G,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC;MAChCO,cAAc,EAAEd,iBAAA,CAAAe,cAAc,CAACmG;KAChC,CAAC,CACH;EACH;EAEA;;;;;EAKA,MAAMC,WAAWA,CAAC5G,OAA4B;IAC5C,IAAI;MACF,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EACpB,IAAI,CAACb,MAAM,EACX,IAAI/B,SAAA,CAAAyH,kBAAkB,CAAC,IAAsB,EAAE,GAAG,EAAE,IAAAhH,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CACnF;MACD,OAAO,IAAI;IACb,CAAC,CAAC,OAAO6G,KAAK,EAAE;MACd;MACA,IAAIA,KAAK,YAAYnI,OAAA,CAAAoI,0BAA0B,EAAE,MAAMD,KAAK;MAC5D,OAAO,KAAK;IACd;EACF;EAEA;;;;;EAKAE,WAAWA,CAAC/G,OAA4B;IACtC,OAAO,IAAIxB,qBAAA,CAAAwI,iBAAiB,CAAC,IAAsB,EAAE,IAAAtH,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC;EACrF;EAEA;;;;;;EAMA,MAAMiH,WAAWA,CAAChB,OAA0B,EAAEjG,OAA4B;IACxE,MAAMkH,UAAU,GAAahF,KAAK,CAACC,OAAO,CAAC8D,OAAO,CAAC,GAAGA,OAAO,GAAG,CAACA,OAAO,CAAC;IACzE,MAAMkB,UAAU,GAAgB,IAAIC,GAAG,CACrC,MAAM,IAAI,CAACL,WAAW,CAAC/G,OAAO,CAAC,CAC5ByC,GAAG,CAAC,CAAC;MAAE1C;IAAI,CAAE,KAAKA,IAAI,CAAC,CACvB2F,OAAO,EAAE,CACb;IACD,OAAOwB,UAAU,CAACG,KAAK,CAACtH,IAAI,IAAIoH,UAAU,CAACG,GAAG,CAACvH,IAAI,CAAC,CAAC;EACvD;EAiBA,MAAMwH,gBAAgBA,CACpBvH,OAAiC;IAEjC,OAAO,MAAM,IAAI,CAACiG,OAAO,CAAC;MACxB,GAAGjG,OAAO;MACVwH,IAAI,EAAExH,OAAO,EAAEwH,IAAI,IAAI;KACxB,CAAC;EACJ;EAEA;;;;;;;;;;;;;EAaA,MAAMC,sBAAsBA,CAACzH,OAAuC;IAClE,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIlC,0BAAA,CAAA4I,+BAA+B,CAAC,IAAsB,EAAE,IAAAhI,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CAC3F;EACH;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BA,MAAM2H,cAAcA,CAClBhE,MAAA,GAA0B,EAAE,EAC5B3D,OAAA,GAA6C,EAAE;IAE/C,MAAM4H,QAAQ,GAAG,EAAE;IACnBA,QAAQ,CAACC,IAAI,CAAC;MAAEC,MAAM,EAAEnE;IAAM,CAAE,CAAC;IAEjC,IAAI,OAAO3D,OAAO,CAAC+H,IAAI,KAAK,QAAQ,EAAE;MACpCH,QAAQ,CAACC,IAAI,CAAC;QAAEG,KAAK,EAAEhI,OAAO,CAAC+H;MAAI,CAAE,CAAC;IACxC;IAEA,IAAI,OAAO/H,OAAO,CAACmF,KAAK,KAAK,QAAQ,EAAE;MACrCyC,QAAQ,CAACC,IAAI,CAAC;QAAEI,MAAM,EAAEjI,OAAO,CAACmF;MAAK,CAAE,CAAC;IAC1C;IAEAyC,QAAQ,CAACC,IAAI,CAAC;MAAEK,MAAM,EAAE;QAAEC,GAAG,EAAE,CAAC;QAAEC,CAAC,EAAE;UAAEC,IAAI,EAAE;QAAC;MAAE;IAAE,CAAE,CAAC;IAErD,MAAMpD,MAAM,GAAG,IAAI,CAACqD,SAAS,CAAgBV,QAAQ,EAAE5H,OAAO,CAAC;IAC/D,MAAM4B,GAAG,GAAG,MAAMqD,MAAM,CAACI,IAAI,EAAE;IAC/B,MAAMJ,MAAM,CAACK,KAAK,EAAE;IACpB,OAAO1D,GAAG,EAAEwG,CAAC,IAAI,CAAC;EACpB;EAgCA,MAAMG,QAAQA,CACZC,GAAQ,EACR7E,MAAA,GAA0B,EAAE,EAC5B3D,OAAA,GAA2B,EAAE;IAE7B,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAInC,UAAA,CAAA4J,iBAAiB,CACnB,IAAsB,EACtBD,GAAqB,EACrB7E,MAAM,EACN,IAAAjE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAC9B,CACF;EACH;EAaA,MAAMiG,OAAOA,CACXjG,OAAiC;IAEjC,MAAMiG,OAAO,GAA2B,MAAM,IAAI,CAACc,WAAW,CAAC/G,OAAO,CAAC,CAAC0F,OAAO,EAAE;IACjF,MAAM8B,IAAI,GAAGxH,OAAO,EAAEwH,IAAI,IAAI,IAAI;IAClC,IAAIA,IAAI,EAAE;MACR,OAAOvB,OAAO;IAChB;IAEA,MAAMyC,MAAM,GAA4BC,MAAM,CAACC,WAAW,CACxD3C,OAAO,CAACxD,GAAG,CAAC,CAAC;MAAE1C,IAAI;MAAEyI;IAAG,CAAE,KAAK,CAACzI,IAAI,EAAE4I,MAAM,CAACE,OAAO,CAACL,GAAG,CAAC,CAAC,CAAC,CAC5D;IAED,OAAOE,MAAM;EACf;EAqBA,MAAMI,gBAAgBA,CACpBnF,MAAuB,EACvB3D,OAAiC;IAEjC,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIhC,iBAAA,CAAA+J,yBAAyB,CAC3B,IAAsB,EACtBpF,MAAM,EACN,IAAAjE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CACZ,CACpB;EACH;EA4BA,MAAMgJ,iBAAiBA,CACrBrF,MAAuB,EACvBI,WAA+B,EAC/B/D,OAAkC;IAElC,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIhC,iBAAA,CAAAiK,0BAA0B,CAC5B,IAAsB,EACtBtF,MAAM,EACNI,WAAW,EACX,IAAArE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CACZ,CACpB;EACH;EAoCA,MAAMkJ,gBAAgBA,CACpBvF,MAAuB,EACvBC,MAA0C,EAC1C5D,OAAiC;IAEjC,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIhC,iBAAA,CAAAmK,yBAAyB,CAC3B,IAAsB,EACtBxF,MAAM,EACNC,MAAM,EACN,IAAAlE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CACZ,CACpB;EACH;EAEA;;;;;;EAMAsI,SAASA,CACPV,QAAA,GAAuB,EAAE,EACzB5H,OAAsC;IAEtC,IAAI,CAACkC,KAAK,CAACC,OAAO,CAACyF,QAAQ,CAAC,EAAE;MAC5B,MAAM,IAAIlJ,OAAA,CAAA0D,yBAAyB,CACjC,4DAA4D,CAC7D;IACH;IAEA,OAAO,IAAI9D,oBAAA,CAAA8K,iBAAiB,CAC1B,IAAI,CAACpI,MAAM,EACX,IAAI,CAACf,CAAC,CAACC,SAAS,EAChB0H,QAAQ,EACR,IAAAlI,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAC9B;EACH;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA2FAqJ,KAAKA,CACHzB,QAAA,GAAuB,EAAE,EACzB5H,OAAA,GAA+B,EAAE;IAEjC;IACA,IAAI,CAACkC,KAAK,CAACC,OAAO,CAACyF,QAAQ,CAAC,EAAE;MAC5B5H,OAAO,GAAG4H,QAAQ;MAClBA,QAAQ,GAAG,EAAE;IACf;IAEA,OAAO,IAAIvJ,eAAA,CAAAiL,YAAY,CAAkB,IAAI,EAAE1B,QAAQ,EAAE,IAAAlI,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC;EACzF;EAEA;;;;;;;;EAQAqD,yBAAyBA,CAACrD,OAA0B;IAClD,OAAO,IAAI5B,WAAA,CAAAmL,sBAAsB,CAAC,IAAsB,EAAE,IAAA7J,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC;EAC1F;EAEA;;;;;;;;EAQAsD,uBAAuBA,CAACtD,OAA0B;IAChD,OAAO,IAAI7B,SAAA,CAAAqL,oBAAoB,CAAC,IAAsB,EAAE,IAAA9J,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC;EACxF;EAEA;;;;;;;;;;;;EAYA,MAAMyJ,KAAKA,CAAC9F,MAAA,GAA0B,EAAE,EAAE3D,OAAA,GAAwB,EAAE;IAClE,OAAO,MAAM,IAAAjB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAIrC,OAAA,CAAA+K,cAAc,CAAC,IAAI,CAACtI,aAAa,EAAEuC,MAAM,EAAE,IAAAjE,OAAA,CAAAqC,cAAc,EAAC,IAAI,EAAE/B,OAAO,CAAC,CAAC,CAC9E;EACH;EAmBA2J,iBAAiBA,CACfC,kBAAsD,EACtD5J,OAAkC;IAElCA,OAAO,GACL,OAAO4J,kBAAkB,KAAK,QAAQ,GAAGA,kBAAkB,GAAG5J,OAAO,IAAI,IAAI,GAAG,EAAE,GAAGA,OAAO;IAE9F,MAAMyG,SAAS,GACbmD,kBAAkB,IAAI,IAAI,GACtB,IAAI,GACJ,OAAOA,kBAAkB,KAAK,QAAQ,GACpC,IAAI,GACJA,kBAAkB;IAE1B,OAAO,IAAInL,4BAAA,CAAAoL,uBAAuB,CAAC,IAAsB,EAAEpD,SAAS,EAAEzG,OAAO,CAAC;EAChF;EAEA;;;;;;;;EAQA,MAAM8J,iBAAiBA,CAACC,WAAmC;IACzD,MAAM,CAACC,KAAK,CAAC,GAAG,MAAM,IAAI,CAACC,mBAAmB,CAAC,CAACF,WAAW,CAAC,CAAC;IAC7D,OAAOC,KAAK;EACd;EAEA;;;;;;;;;EASA,MAAMC,mBAAmBA,CAACC,YAAsC;IAC9D,OAAO,MAAM,IAAAnL,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAI5B,QAAA,CAAA+K,4BAA4B,CAAC,IAAsB,EAAED,YAAY,CAAC,CACvE;EACH;EAEA;;;;;;;EAOA,MAAME,eAAeA,CAACrK,IAAY;IAChC,OAAO,MAAM,IAAAhB,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAI3B,MAAA,CAAAgL,wBAAwB,CAAC,IAAsB,EAAEtK,IAAI,CAAC,CAC3D;EACH;EAEA;;;;;;;;EAQA,MAAMuK,iBAAiBA,CAACvK,IAAY,EAAEwK,UAAoB;IACxD,OAAO,MAAM,IAAAxL,mBAAA,CAAA8C,gBAAgB,EAC3B,IAAI,CAACb,MAAM,EACX,IAAI1B,QAAA,CAAAkL,0BAA0B,CAAC,IAAsB,EAAEzK,IAAI,EAAEwK,UAAU,CAAC,CACzE;EACH;;AAznCFE,OAAA,CAAA7K,UAAA,GAAAA,UAAA","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}